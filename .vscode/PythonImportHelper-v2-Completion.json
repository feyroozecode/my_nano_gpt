[
    {
        "label": "tiktoken",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tiktoken",
        "description": "tiktoken",
        "detail": "tiktoken",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Bigram",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "Bigram",
        "description": "Bigram",
        "detail": "Bigram",
        "documentation": {}
    },
    {
        "label": "BigramLanguagBigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLanguagBigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLanguagBigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLanguagBigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLanguageModel",
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "isExtraImport": true,
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "BigramLang",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "BigramLang",
        "description": "BigramLang",
        "detail": "BigramLang",
        "documentation": {}
    },
    {
        "label": "BigramLanguageModel",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "BigramLanguageModel",
        "description": "BigramLanguageModel",
        "detail": "BigramLanguageModel",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114529",
        "description": ".history.engin_20231127114529",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114529",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114540",
        "description": ".history.engin_20231127114540",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114540",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114542",
        "description": ".history.engin_20231127114542",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114542",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114546",
        "description": ".history.engin_20231127114546",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114546",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114548",
        "description": ".history.engin_20231127114548",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114548",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114602",
        "description": ".history.engin_20231127114602",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114602",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114603",
        "description": ".history.engin_20231127114603",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114603",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114614",
        "description": ".history.engin_20231127114614",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114614",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114618",
        "description": ".history.engin_20231127114618",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114618",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": ".history.engin_20231127114624",
        "description": ".history.engin_20231127114624",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": ".history.engin_20231127114624",
        "documentation": {}
    },
    {
        "label": "BigramLanguageModel",
        "kind": 6,
        "importPath": "bigran_lm",
        "description": "bigran_lm",
        "peekOfCode": "class BigramLanguageModel(nn.Module):\n    def __init__(self, vocab_size):\n        super().__init__()\n        # each token directly read\n        # s off the logits for the nex token a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n    def forward(self, idx, targets):\n        # idx and targets are both (B, T) tensor of integers \n        logits = self.token_embedding_table(idx)  # (B, T, C)\n        return logits",
        "detail": "bigran_lm",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# encode a text\nmy_text = \"\"\"\n    Salam Aleykoum bonjour monsieur ali, Ceci est un texte de test\n    Ce texte est ecrit juste pour tester la froce des LLM comme chatGpt\n    Et aussi pour apprendre comment developer un nano-gpt(petit reseau de GPT) baser sur gpt2 \n    Ce programme utilise tiktoken un paquet OpenSource developper par OpenAI pour tokenizer notre texte\n    La tokenisation cinsiste a encoder notre texte et l'enumer avec des nombre pour etre plus facile a manipuler et predire le mot suivant .etc..\n    Nous utilisons aussi pyTorch une des meilleur bibliotheque python pour entrainer nos donnees sur des large ndodel de langage.",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "my_text",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "my_text = \"\"\"\n    Salam Aleykoum bonjour monsieur ali, Ceci est un texte de test\n    Ce texte est ecrit juste pour tester la froce des LLM comme chatGpt\n    Et aussi pour apprendre comment developer un nano-gpt(petit reseau de GPT) baser sur gpt2 \n    Ce programme utilise tiktoken un paquet OpenSource developper par OpenAI pour tokenizer notre texte\n    La tokenisation cinsiste a encoder notre texte et l'enumer avec des nombre pour etre plus facile a manipuler et predire le mot suivant .etc..\n    Nous utilisons aussi pyTorch une des meilleur bibliotheque python pour entrainer nos donnees sur des large ndodel de langage.\n    Ce programme est a titre experimentatle  il est developper en utilisant le langage python. \n    \"\"\"\nencoded_txt = enc.encode(my_text)",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded text is : \", encoded_txt)\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"bonjour monsieur ali\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"bonjour monsieur ali\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "sample_txt = \"bonjour monsieur ali\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\nprint(data.shape, data.dtype)\nprint(data[:1000])",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\nprint(data.shape, data.dtype)\nprint(data[:1000])",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\nprint(data.shape, data.dtype)\nprint(data[:1000])",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "char_generators",
        "description": "char_generators",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\nprint(data.shape, data.dtype)\nprint(data[:1000])",
        "detail": "char_generators",
        "documentation": {}
    },
    {
        "label": "get_batch",
        "kind": 2,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "def get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')\nprint(xb.shape)  ",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "enc",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "enc = tiktoken.get_encoding(\"gpt2\")             # encoding type \nprint(enc.n_vocab)\n# importing the datas\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    my_text = f.read()\nprint(\"length of dataset in characters: \", len(my_text))\n# let's look at the first 1000 characters\nprint(my_text[:1000])\n# encode a text\nencoded_txt = enc.encode(my_text)",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "encoded_txt",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "encoded_txt = enc.encode(my_text)\nprint(\"Encoded first 1000 char in encoded text is : \", encoded_txt[:1000])\n#decode\ndecoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  ",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "decoded_txt",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "decoded_txt = enc.decode(encoded_txt)\nprint(\"Decoded text is : \", decoded_txt)\nchars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "chars_lngtext",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "chars_lngtext = sorted(list(set(my_text)))  # sorted list by chars \nchars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "chars_vocab_size",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "chars_vocab_size = len(chars_lngtext)       # vocab words char length\nprint(\"chars of my text : \", chars_lngtext , \"\\nand size is \", chars_vocab_size, \"chars \")\njoined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "joined_text",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "joined_text = ''.join(chars_lngtext)        # Joined chars \nprint(\"joinded text is : \", joined_text)  \n# A dictionary where characters are keys, and their corresponding indices (integers) are values.\nstoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "stoi",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "stoi = {\n    char:i for i,char in enumerate(chars_lngtext)\n}\n# 'itos' is the inverse dictionary where indices are keys, and the characters are values.\nitos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "itos",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "itos = {\n    i: char for i, char in enumerate(chars_lngtext)\n}\n# 'encode' is a lambda function that takes a string 's' and returns a list of integers.\n# It uses list comprehension to map each character in the string to its corresponding integer using the 'stoi' dictionary.\nencode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "encode",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "encode = lambda s: [stoi[c] for c in s ]\n# 'decode' is a lambda function that takes a list of integers 'l' and returns a string.\n# It uses list comprehension to map each integer in the list to its corresponding character using the 'itos' dictionary,\n# and then joins the characters into a string using the ''.join() method\ndecode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "decode",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "decode = lambda list: ''.join([itos[i] for i in list ])\n# test encode and decode\nsample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "sample_txt",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "sample_txt = \"Very well; and could be content to give him good\" # for train                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  N    M\nprint(\"0-> BEFORE ENCODE => new text is : \", sample_txt)\nencode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "encode_str",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "encode_str = encode(sample_txt)\nprint(\"1-> AFTER ENCODE => the new encoded is \", encode_str)\ndecoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "decoded_str",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "decoded_str = decode(encode_str)\nprint(\"2-> FINAL DECODE IT => the text is =\", decoded_str)\n# torch \ndata = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "data = torch.tensor(encode(my_text), dtype=torch.long)\n# show the data shape and data type\nprint(\"\\nData Shape : \",data.shape, \"\\nData Type :\", data.dtype)\n# print tenser data left then 1000\nprint(\"tensored data left then 1000 only \",data[:1000])\n# Lets now split up the data into train and validation sets\nnet1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "net1",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "net1 = int(0.9 * len(data)) # first 90% will be train , rest => val\ntrain_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target ",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "train_data = data[:net1]    # data to train is 90% of total datas\nval_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "val_data = data[net1:]      # data to val is 10% of total datas\nblock_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "block_size = 8              # 8 digit chararacter(corresponfing to the vocab digit values) will be train to get 1 target next\ntrain_data[:block_size+1]   # 8 inputs => char + 1 target]\nprint(\"tensor block size : \", train_data[:block_size+1])\n# now lets train the data target when is gived context\n# x is the input(context)\n# y is the target \n# loop it in range of block_size and show the context and the target \nx = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "x = train_data[:block_size]\ny = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "y = train_data[:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target : {target}\")\n#\n# Manual torch using \nprint(\"\\n --- MANUAL torch feed to find next value using context  \\n\")\ntorch.manual_seed(1337)\nbatch_size = 4 # how many independent sequences will we process in parallel?",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "batch_size = 4 # how many independent sequences will we process in parallel?\nblock_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # ",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "block_size",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "block_size = 8 # what is the maximum context length for predictions?\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,)) # ix is the \n    x = torch.stack([data[i:i+block_size] for i in ix])       # \n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # \n    return x, y\nxb, yb = get_batch('train')  # \nprint('inputs:')",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "model = BigramLanguageModel(chars_vocab_size)\nout = model(xb, yb)\nprint(out.shape)",
        "detail": "engin",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": "engin",
        "description": "engin",
        "peekOfCode": "out = model(xb, yb)\nprint(out.shape)",
        "detail": "engin",
        "documentation": {}
    }
]